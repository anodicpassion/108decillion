import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Reshape, Input, Flatten, BatchNormalization
from sklearn.model_selection import train_test_split


import time, datetime
from fyers_apiv3 import fyersModel
import authenticator
client_id = "ZHQ4IJL7TI-100"
access_token = authenticator.authenticate()

fyers = fyersModel.FyersModel(client_id=client_id, is_async=False, token=access_token, log_path="")
market_status = fyers.market_status()

"Market: " + market_status["marketStatus"][1]['status']


import matplotlib.pyplot as plt
import numpy as np


from indicators.syncind import SyncInd
from indicators.classic import SMA, Alligator, SmoothMA, RSI, MACD, ATR, WMA, EMA, RMA, VolumeROC, KAMA
from indicators.candle import OHLC
from indicators import epoch_to_time


date_yesterday = (datetime.datetime.now() - datetime.timedelta(days=1)).strftime("%Y-%m-%d")
date_100_p = (datetime.datetime.now() - datetime.timedelta(days=100)).strftime("%Y-%m-%d")
date_yesterday, date_100_p


symbol = "NSE:NIFTY50-INDEX"
resolution_1 = "1"

response_1 = fyers.history(data={
                                "symbol": symbol,
                                "resolution": resolution_1,
                                "date_format": "1",
                                "range_from": date_100_p,
                                "range_to": date_yesterday,
                                "cont_flag": "1"
                        })




def remove_duplicates(resp_candels):
    date_temp = []
    final_candles_list = []
    for i in resp_candels:
        if i[0] not in date_temp:
            final_candles_list.append(i)
            date_temp.append(i[0])
    del date_temp
    return final_candles_list


final_candles_list_1 = remove_duplicates(response_1['candles'])
len(final_candles_list_1)


candles_1 = np.array(final_candles_list_1)
candles_1.shape


sync_1 = SyncInd(
    SMA(5),
    Alligator(show_jaw=False, show_teeth=False),
    # EMA(),
    KAMA(highlight=True),
)

for c in candles_1:
    sync_1.append(c)
sync_1.data().shape



X, y = [], []
start_ind = 1 # should be 1 or greater than 1; otherwise logic assumes first candle as the last candle
back_look = 5
sync_data = sync_1.data()

def append_to_final_data(data):
    for ind, i in enumerate(data[start_ind : -back_look]):
        temp = []
        first_candle = data[start_ind+ind-1]
        
        last_candle = data[start_ind+ind+back_look-1]
        if epoch_to_time(first_candle[0]).split(" ")[0] != epoch_to_time(last_candle[0]).split(" ")[0]:
            # print(f'''day change detected: {epoch_to_time(first_candle[0]).split(" ")[0]} to {epoch_to_time(last_candle[0]).split(" ")[0]}''')
            continue
            
        for j in data[start_ind+ind : start_ind+ind+back_look]:
            temp.append([round(a, 2) for a in (j[1:]-first_candle[1:]).tolist()[5:]])    
        y.append([round(a, 2) for a in (data[start_ind+ind+back_look][1:] - first_candle[1:]).tolist()[5:]])
        X.append(temp)


append_to_final_data(sync_data[100:])

X = np.array(X, dtype=np.float16)
y = np.array(y, dtype=np.float16)

"X.shape", X.shape, "y.shape", y.shape


X[0:2]


X[1:2]


split_len = 20000
X_train, X_test = X[:split_len], X[split_len:]
y_train, y_test = y[:split_len], y[split_len:]
"X_train.shape", X_train.shape, "X_test.shape", X_test.shape, "y_train.shape", y_train.shape, "y_test.shape", y_test.shape


model = Sequential()
model.add(Input(shape=(5, 4)))
model.add(LSTM(200, activation='tanh', return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(150, activation='tanh'))
model.add(Dropout(0.2))
model.add(Dense(4))
# model.add(Reshape((1, 4)))
model.compile(optimizer='adam', loss='mse')


history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_split=0.2)


y_pred = model.predict(X_test)
y_pred


plt.plot(y_test[:50, 0], label='C1 Open', color="pink")
plt.plot(y_pred[:50, 0], label='C1 P_Open', color="darkred")
plt.legend()
plt.show()


model.save("Mar_11_01.keras")


y_pred[:50, 0].shape


print("Actual\t\tPredicted\tError")
print("-"*40)
error_list = []
for actual, predicted in zip(y_pred, y_test):
    error = round(float((actual-predicted)[0]), 2)
    print(f"{round(float(actual[0]), 2)}\t\t{round(float(predicted[0]), 2)}\t\t{error}")
    error_list.append(error)


print("Max\tMin\tMean\tP_err\tN_err\tTotal")
print("-"*45)
error_offset_pos = 5
error_offset_neg = 5
print(f"{max(error_list)}\t{min(error_list)}\t{round(sum(error_list)/len(error_list), 2)}\t{len([a for a in error_list if a > error_offset_pos])}\t{len([a for a in error_list if a < -error_offset_neg])}\t{len(error_list)}")
