{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce590a0-ce41-4eeb-9268-7a37a3c2c9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3c00666-3eeb-40cc-aeff-732b4188c9ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Jaw ‌Alligator‌</th>\n",
       "      <th>Teeth ‌Alligator</th>\n",
       "      <th>Lips ‌Alligator</th>\n",
       "      <th>MA5</th>\n",
       "      <th>MA15</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Volume Change Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Sep 25 2024 10:57:00 GMT+0530 (India Stand...</td>\n",
       "      <td>128.35</td>\n",
       "      <td>128.36</td>\n",
       "      <td>128.27</td>\n",
       "      <td>128.34</td>\n",
       "      <td>127.57</td>\n",
       "      <td>127.87</td>\n",
       "      <td>128.47</td>\n",
       "      <td>128.42</td>\n",
       "      <td>128.54</td>\n",
       "      <td>8697.0</td>\n",
       "      <td>-68.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed Sep 25 2024 10:58:00 GMT+0530 (India Stand...</td>\n",
       "      <td>128.34</td>\n",
       "      <td>128.40</td>\n",
       "      <td>128.32</td>\n",
       "      <td>128.39</td>\n",
       "      <td>127.58</td>\n",
       "      <td>127.96</td>\n",
       "      <td>128.44</td>\n",
       "      <td>128.38</td>\n",
       "      <td>128.55</td>\n",
       "      <td>18923.0</td>\n",
       "      <td>-85.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed Sep 25 2024 10:59:00 GMT+0530 (India Stand...</td>\n",
       "      <td>128.37</td>\n",
       "      <td>128.39</td>\n",
       "      <td>128.30</td>\n",
       "      <td>128.34</td>\n",
       "      <td>127.60</td>\n",
       "      <td>128.06</td>\n",
       "      <td>128.42</td>\n",
       "      <td>128.36</td>\n",
       "      <td>128.54</td>\n",
       "      <td>17725.0</td>\n",
       "      <td>-63.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wed Sep 25 2024 11:00:00 GMT+0530 (India Stand...</td>\n",
       "      <td>128.34</td>\n",
       "      <td>128.35</td>\n",
       "      <td>128.30</td>\n",
       "      <td>128.35</td>\n",
       "      <td>127.61</td>\n",
       "      <td>128.14</td>\n",
       "      <td>128.41</td>\n",
       "      <td>128.35</td>\n",
       "      <td>128.52</td>\n",
       "      <td>4863.0</td>\n",
       "      <td>-95.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed Sep 25 2024 11:01:00 GMT+0530 (India Stand...</td>\n",
       "      <td>128.35</td>\n",
       "      <td>128.40</td>\n",
       "      <td>128.30</td>\n",
       "      <td>128.35</td>\n",
       "      <td>127.65</td>\n",
       "      <td>128.18</td>\n",
       "      <td>128.39</td>\n",
       "      <td>128.35</td>\n",
       "      <td>128.49</td>\n",
       "      <td>10833.0</td>\n",
       "      <td>-74.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>Fri Sep 27 2024 15:25:00 GMT+0530 (India Stand...</td>\n",
       "      <td>135.14</td>\n",
       "      <td>135.38</td>\n",
       "      <td>135.05</td>\n",
       "      <td>135.17</td>\n",
       "      <td>135.74</td>\n",
       "      <td>135.88</td>\n",
       "      <td>135.50</td>\n",
       "      <td>135.27</td>\n",
       "      <td>135.70</td>\n",
       "      <td>96944.0</td>\n",
       "      <td>-58.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>Fri Sep 27 2024 15:26:00 GMT+0530 (India Stand...</td>\n",
       "      <td>135.15</td>\n",
       "      <td>135.37</td>\n",
       "      <td>135.10</td>\n",
       "      <td>135.10</td>\n",
       "      <td>135.75</td>\n",
       "      <td>135.88</td>\n",
       "      <td>135.45</td>\n",
       "      <td>135.23</td>\n",
       "      <td>135.64</td>\n",
       "      <td>123132.0</td>\n",
       "      <td>-33.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>Fri Sep 27 2024 15:27:00 GMT+0530 (India Stand...</td>\n",
       "      <td>135.15</td>\n",
       "      <td>135.30</td>\n",
       "      <td>135.06</td>\n",
       "      <td>135.30</td>\n",
       "      <td>135.76</td>\n",
       "      <td>135.88</td>\n",
       "      <td>135.40</td>\n",
       "      <td>135.23</td>\n",
       "      <td>135.61</td>\n",
       "      <td>119850.0</td>\n",
       "      <td>-36.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>Fri Sep 27 2024 15:28:00 GMT+0530 (India Stand...</td>\n",
       "      <td>135.24</td>\n",
       "      <td>135.30</td>\n",
       "      <td>135.05</td>\n",
       "      <td>135.10</td>\n",
       "      <td>135.77</td>\n",
       "      <td>135.87</td>\n",
       "      <td>135.36</td>\n",
       "      <td>135.17</td>\n",
       "      <td>135.55</td>\n",
       "      <td>122398.0</td>\n",
       "      <td>-57.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>Fri Sep 27 2024 15:29:00 GMT+0530 (India Stand...</td>\n",
       "      <td>135.24</td>\n",
       "      <td>135.25</td>\n",
       "      <td>135.05</td>\n",
       "      <td>135.15</td>\n",
       "      <td>135.78</td>\n",
       "      <td>135.83</td>\n",
       "      <td>135.32</td>\n",
       "      <td>135.16</td>\n",
       "      <td>135.50</td>\n",
       "      <td>141743.0</td>\n",
       "      <td>-35.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1023 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Date    Open    High  \\\n",
       "0     Wed Sep 25 2024 10:57:00 GMT+0530 (India Stand...  128.35  128.36   \n",
       "1     Wed Sep 25 2024 10:58:00 GMT+0530 (India Stand...  128.34  128.40   \n",
       "2     Wed Sep 25 2024 10:59:00 GMT+0530 (India Stand...  128.37  128.39   \n",
       "3     Wed Sep 25 2024 11:00:00 GMT+0530 (India Stand...  128.34  128.35   \n",
       "4     Wed Sep 25 2024 11:01:00 GMT+0530 (India Stand...  128.35  128.40   \n",
       "...                                                 ...     ...     ...   \n",
       "1018  Fri Sep 27 2024 15:25:00 GMT+0530 (India Stand...  135.14  135.38   \n",
       "1019  Fri Sep 27 2024 15:26:00 GMT+0530 (India Stand...  135.15  135.37   \n",
       "1020  Fri Sep 27 2024 15:27:00 GMT+0530 (India Stand...  135.15  135.30   \n",
       "1021  Fri Sep 27 2024 15:28:00 GMT+0530 (India Stand...  135.24  135.30   \n",
       "1022  Fri Sep 27 2024 15:29:00 GMT+0530 (India Stand...  135.24  135.25   \n",
       "\n",
       "         Low   Close  Jaw ‌Alligator‌  Teeth ‌Alligator  Lips ‌Alligator  \\\n",
       "0     128.27  128.34           127.57            127.87           128.47   \n",
       "1     128.32  128.39           127.58            127.96           128.44   \n",
       "2     128.30  128.34           127.60            128.06           128.42   \n",
       "3     128.30  128.35           127.61            128.14           128.41   \n",
       "4     128.30  128.35           127.65            128.18           128.39   \n",
       "...      ...     ...              ...               ...              ...   \n",
       "1018  135.05  135.17           135.74            135.88           135.50   \n",
       "1019  135.10  135.10           135.75            135.88           135.45   \n",
       "1020  135.06  135.30           135.76            135.88           135.40   \n",
       "1021  135.05  135.10           135.77            135.87           135.36   \n",
       "1022  135.05  135.15           135.78            135.83           135.32   \n",
       "\n",
       "         MA5    MA15    Volume  Volume Change Percentage  \n",
       "0     128.42  128.54    8697.0                    -68.27  \n",
       "1     128.38  128.55   18923.0                    -85.49  \n",
       "2     128.36  128.54   17725.0                    -63.08  \n",
       "3     128.35  128.52    4863.0                    -95.12  \n",
       "4     128.35  128.49   10833.0                    -74.49  \n",
       "...      ...     ...       ...                       ...  \n",
       "1018  135.27  135.70   96944.0                    -58.69  \n",
       "1019  135.23  135.64  123132.0                    -33.40  \n",
       "1020  135.23  135.61  119850.0                    -36.70  \n",
       "1021  135.17  135.55  122398.0                    -57.00  \n",
       "1022  135.16  135.50  141743.0                    -35.77  \n",
       "\n",
       "[1023 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/zeel/ZEEL (20240930093400000 _ 20240925105700000).csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47362551-bca5-46fa-bcbe-db105f58ca3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Jaw ‌Alligator‌',\n",
       "       'Teeth ‌Alligator', 'Lips ‌Alligator', 'MA5', 'MA15', 'Volume',\n",
       "       'Volume Change Percentage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99fd3370-aec5-4248-a1a4-be31cb610c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_numpy()\n",
    "data = data[:, 1:] # removing the dates column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a9cf80-febd-43ff-9dd9-a1efbd498f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[128.35, 128.36, 128.27, ..., 128.54, 8697.0, -68.27],\n",
       "       [128.34, 128.4, 128.32, ..., 128.55, 18923.0, -85.49],\n",
       "       [128.37, 128.39, 128.3, ..., 128.54, 17725.0, -63.08],\n",
       "       ...,\n",
       "       [135.15, 135.3, 135.06, ..., 135.61, 119850.0, -36.7],\n",
       "       [135.24, 135.3, 135.05, ..., 135.55, 122398.0, -57.0],\n",
       "       [135.24, 135.25, 135.05, ..., 135.5, 141743.0, -35.77]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9d9f6c4b-1d30-4a7f-89ee-f18a40b1b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "013061b6-cb8a-4910-a841-5ff12f8ec05b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_candles_count = 5\n",
    "next_candles_count = 3\n",
    "\n",
    "for idx, row in enumerate(data[last_candles_count-1 : \n",
    "    -(next_candles_count)]):\n",
    "    idx = idx + last_candles_count \n",
    "    first_open = data[idx-last_candles_count-1][0]\n",
    "    first_jaw = data[idx-last_candles_count-1][4]\n",
    "    first_lip = data[idx-last_candles_count-1][6]\n",
    "    first_teeth = data[idx-last_candles_count-1][5]\n",
    "    first_ma5 = data[idx-last_candles_count-1][7]\n",
    "    first_ma15 = data[idx-last_candles_count-1][8]\n",
    "    first_volumn = data[idx-last_candles_count-1][9]\n",
    "    first_volumn_change = data[idx-last_candles_count-1][10]\n",
    "    last_candles = []\n",
    "    for candle in data[idx-last_candles_count : idx]:\n",
    "        temp = []\n",
    "        temp.append(round(candle[0]-first_open, 2))\n",
    "        temp.append(round(candle[1]-first_open, 2))\n",
    "        temp.append(round(candle[2]-first_open, 2))\n",
    "        temp.append(round(candle[3]-first_open, 2))\n",
    "        temp.append(round(candle[4]-first_jaw, 2))\n",
    "        temp.append(round(candle[5]-first_teeth, 2))\n",
    "        temp.append(round(candle[6]-first_lip, 2))\n",
    "        temp.append(round(candle[7]-first_ma5, 2))\n",
    "        temp.append(round(candle[8]-first_ma15, 2))\n",
    "        temp.append(round(candle[9]-first_volumn, 2))\n",
    "        temp.append(round(candle[10]-first_volumn_change, 2))\n",
    "        # for param in candle:\n",
    "        #     temp.append(round(param-first_open, 2))\n",
    "        last_candles.append(temp)\n",
    "    X.append(last_candles)\n",
    "    next_candles = []\n",
    "    for candle in data[idx: idx+next_candles_count]:\n",
    "        temp = []\n",
    "        temp.append(round(candle[0]-first_open, 2))\n",
    "        # temp.append(round(candle[1]-first_open, 2))\n",
    "        # temp.append(round(candle[2]-first_open, 2))\n",
    "        # temp.append(round(candle[3]-first_open, 2))\n",
    "        # temp.append(round(candle[4]-first_jaw, 2))\n",
    "        # temp.append(round(candle[5]-first_teeth, 2))\n",
    "        # temp.append(round(candle[6]-first_lip, 2))\n",
    "        # temp.append(round(candle[7]-first_ma5, 2))\n",
    "        # temp.append(round(candle[8]-first_ma15, 2))\n",
    "        # temp.append(round(candle[9]-first_volumn, 2))\n",
    "        # temp.append(round(candle[10]-first_volumn_change, 2))\n",
    "        \n",
    "        # for param in candle:\n",
    "        #     temp.append(round(param-first_open, 2))\n",
    "        next_candles.append(temp)\n",
    "    y.append(next_candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d29aadc2-b3c1-411c-8738-e85cd89120ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-6.89,\n",
       "  -6.88,\n",
       "  -6.97,\n",
       "  -6.9,\n",
       "  -8.21,\n",
       "  -7.96,\n",
       "  -6.85,\n",
       "  -6.74,\n",
       "  -6.96,\n",
       "  -133046.0,\n",
       "  -32.5],\n",
       " [-6.9,\n",
       "  -6.84,\n",
       "  -6.92,\n",
       "  -6.85,\n",
       "  -8.2,\n",
       "  -7.87,\n",
       "  -6.88,\n",
       "  -6.78,\n",
       "  -6.95,\n",
       "  -122820.0,\n",
       "  -49.72],\n",
       " [-6.87,\n",
       "  -6.85,\n",
       "  -6.94,\n",
       "  -6.9,\n",
       "  -8.18,\n",
       "  -7.77,\n",
       "  -6.9,\n",
       "  -6.8,\n",
       "  -6.96,\n",
       "  -124018.0,\n",
       "  -27.31],\n",
       " [-6.9,\n",
       "  -6.89,\n",
       "  -6.94,\n",
       "  -6.89,\n",
       "  -8.17,\n",
       "  -7.69,\n",
       "  -6.91,\n",
       "  -6.81,\n",
       "  -6.98,\n",
       "  -136880.0,\n",
       "  -59.35],\n",
       " [-6.89,\n",
       "  -6.84,\n",
       "  -6.94,\n",
       "  -6.89,\n",
       "  -8.13,\n",
       "  -7.65,\n",
       "  -6.93,\n",
       "  -6.81,\n",
       "  -7.01,\n",
       "  -130910.0,\n",
       "  -38.72]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29144c88-2d0e-43c8-ac77-d7164ac23808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-6.86], [-6.74], [-6.88]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d003fa1-72ac-4682-ab31-a9b8812dada7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      " [[128.35 128.36 128.27 128.34 127.57 127.87 128.47 128.42 128.54 8697.0\n",
      "  -68.27]\n",
      " [128.34 128.4 128.32 128.39 127.58 127.96 128.44 128.38 128.55 18923.0\n",
      "  -85.49]\n",
      " [128.37 128.39 128.3 128.34 127.6 128.06 128.42 128.36 128.54 17725.0\n",
      "  -63.08]\n",
      " [128.34 128.35 128.3 128.35 127.61 128.14 128.41 128.35 128.52 4863.0\n",
      "  -95.12]\n",
      " [128.35 128.4 128.3 128.35 127.65 128.18 128.39 128.35 128.49 10833.0\n",
      "  -74.49]\n",
      " [128.38 128.5 128.24 128.49 127.68 128.22 128.38 128.38 128.48 53924.0\n",
      "  33.19]\n",
      " [128.5 128.58 128.32 128.32 127.71 128.27 128.38 128.37 128.46 70777.0\n",
      "  291.9]\n",
      " [128.36 128.6 128.36 128.6 127.75 128.33 128.39 128.42 128.47 75204.0\n",
      "  33.82]\n",
      " [128.7 128.95 128.68 128.95 127.79 128.36 128.41 128.54 128.48 150502.0\n",
      "  584.57]]\n",
      "\n",
      "X: [[-6.89, -6.88, -6.97, -6.9, -8.21, -7.96, -6.85, -6.74, -6.96, -133046.0, -32.5], [-6.9, -6.84, -6.92, -6.85, -8.2, -7.87, -6.88, -6.78, -6.95, -122820.0, -49.72], [-6.87, -6.85, -6.94, -6.9, -8.18, -7.77, -6.9, -6.8, -6.96, -124018.0, -27.31], [-6.9, -6.89, -6.94, -6.89, -8.17, -7.69, -6.91, -6.81, -6.98, -136880.0, -59.35], [-6.89, -6.84, -6.94, -6.89, -8.13, -7.65, -6.93, -6.81, -7.01, -130910.0, -38.72]]\n",
      "\n",
      "y: [[-6.86], [-6.74], [-6.88]]\n"
     ]
    }
   ],
   "source": [
    "print(\"data:\\n\", data[:9])\n",
    "print(\"\\nX:\", X[0])\n",
    "print(\"\\ny:\", y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dcea559-d481-4404-ad98-0e19ecd82ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Reshape, InputLayer, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3632bc20-cbf5-45e2-aa19-3423fabcbb7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1016, 5, 11), dtype=float32, numpy=\n",
       " array([[[-6.89000e+00, -6.88000e+00, -6.97000e+00, ..., -6.96000e+00,\n",
       "          -1.33046e+05, -3.25000e+01],\n",
       "         [-6.90000e+00, -6.84000e+00, -6.92000e+00, ..., -6.95000e+00,\n",
       "          -1.22820e+05, -4.97200e+01],\n",
       "         [-6.87000e+00, -6.85000e+00, -6.94000e+00, ..., -6.96000e+00,\n",
       "          -1.24018e+05, -2.73100e+01],\n",
       "         [-6.90000e+00, -6.89000e+00, -6.94000e+00, ..., -6.98000e+00,\n",
       "          -1.36880e+05, -5.93500e+01],\n",
       "         [-6.89000e+00, -6.84000e+00, -6.94000e+00, ..., -7.01000e+00,\n",
       "          -1.30910e+05, -3.87200e+01]],\n",
       " \n",
       "        [[-1.00000e-02,  5.00000e-02, -3.00000e-02, ...,  1.00000e-02,\n",
       "           1.02260e+04, -1.72200e+01],\n",
       "         [ 2.00000e-02,  4.00000e-02, -5.00000e-02, ...,  0.00000e+00,\n",
       "           9.02800e+03,  5.19000e+00],\n",
       "         [-1.00000e-02,  0.00000e+00, -5.00000e-02, ..., -2.00000e-02,\n",
       "          -3.83400e+03, -2.68500e+01],\n",
       "         [ 0.00000e+00,  5.00000e-02, -5.00000e-02, ..., -5.00000e-02,\n",
       "           2.13600e+03, -6.22000e+00],\n",
       "         [ 3.00000e-02,  1.50000e-01, -1.10000e-01, ..., -6.00000e-02,\n",
       "           4.52270e+04,  1.01460e+02]],\n",
       " \n",
       "        [[ 3.00000e-02,  5.00000e-02, -4.00000e-02, ..., -1.00000e-02,\n",
       "          -1.19800e+03,  2.24100e+01],\n",
       "         [ 0.00000e+00,  1.00000e-02, -4.00000e-02, ..., -3.00000e-02,\n",
       "          -1.40600e+04, -9.63000e+00],\n",
       "         [ 1.00000e-02,  6.00000e-02, -4.00000e-02, ..., -6.00000e-02,\n",
       "          -8.09000e+03,  1.10000e+01],\n",
       "         [ 4.00000e-02,  1.60000e-01, -1.00000e-01, ..., -7.00000e-02,\n",
       "           3.50010e+04,  1.18680e+02],\n",
       "         [ 1.60000e-01,  2.40000e-01, -2.00000e-02, ..., -9.00000e-02,\n",
       "           5.18540e+04,  3.77390e+02]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.00000e-01,  2.00000e-02, -4.70000e-01, ..., -2.00000e-02,\n",
       "           7.22010e+04, -9.68800e+01],\n",
       "         [-3.10000e-01, -3.10000e-01, -9.40000e-01, ..., -6.00000e-02,\n",
       "           2.51420e+04,  3.46900e+01],\n",
       "         [-6.10000e-01, -5.50000e-01, -9.20000e-01, ..., -1.00000e-01,\n",
       "          -6.69560e+04, -8.36300e+01],\n",
       "         [-8.50000e-01, -6.20000e-01, -9.50000e-01, ..., -1.40000e-01,\n",
       "           2.87500e+04, -5.79900e+01],\n",
       "         [-7.70000e-01, -6.20000e-01, -9.50000e-01, ..., -2.20000e-01,\n",
       "          -5.36280e+04, -9.99400e+01]],\n",
       " \n",
       "        [[-2.10000e-01, -2.10000e-01, -8.40000e-01, ..., -4.00000e-02,\n",
       "          -4.70590e+04,  1.31570e+02],\n",
       "         [-5.10000e-01, -4.50000e-01, -8.20000e-01, ..., -8.00000e-02,\n",
       "          -1.39157e+05,  1.32500e+01],\n",
       "         [-7.50000e-01, -5.20000e-01, -8.50000e-01, ..., -1.20000e-01,\n",
       "          -4.34510e+04,  3.88900e+01],\n",
       "         [-6.70000e-01, -5.20000e-01, -8.50000e-01, ..., -2.00000e-01,\n",
       "          -1.25829e+05, -3.06000e+00],\n",
       "         [-7.60000e-01, -5.20000e-01, -8.50000e-01, ..., -2.60000e-01,\n",
       "          -2.46195e+05, -4.07700e+01]],\n",
       " \n",
       "        [[-3.00000e-01, -2.40000e-01, -6.10000e-01, ..., -4.00000e-02,\n",
       "          -9.20980e+04, -1.18320e+02],\n",
       "         [-5.40000e-01, -3.10000e-01, -6.40000e-01, ..., -8.00000e-02,\n",
       "           3.60800e+03, -9.26800e+01],\n",
       "         [-4.60000e-01, -3.10000e-01, -6.40000e-01, ..., -1.60000e-01,\n",
       "          -7.87700e+04, -1.34630e+02],\n",
       "         [-5.50000e-01, -3.10000e-01, -6.40000e-01, ..., -2.20000e-01,\n",
       "          -1.99136e+05, -1.72340e+02],\n",
       "         [-5.40000e-01, -3.20000e-01, -5.90000e-01, ..., -2.80000e-01,\n",
       "          -1.72948e+05, -1.47050e+02]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1016, 3, 1), dtype=float32, numpy=\n",
       " array([[[-6.86],\n",
       "         [-6.74],\n",
       "         [-6.88]],\n",
       " \n",
       "        [[ 0.15],\n",
       "         [ 0.01],\n",
       "         [ 0.35]],\n",
       " \n",
       "        [[ 0.02],\n",
       "         [ 0.36],\n",
       "         [ 0.72]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.86],\n",
       "         [-0.85],\n",
       "         [-0.85]],\n",
       " \n",
       "        [[-0.75],\n",
       "         [-0.75],\n",
       "         [-0.66]],\n",
       " \n",
       "        [[-0.54],\n",
       "         [-0.45],\n",
       "         [-0.45]]], dtype=float32)>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.constant(X, dtype=tf.float32)\n",
    "y = tf.constant(y, dtype=tf.float32)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b8ad62a-c125-4191-bedf-2524d60a1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(5, 11), activation='relu', return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(LSTM(150, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(3))\n",
    "# model.add(Reshape((3, 11)))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86ae9899-5990-474c-bcfc-b80603a69bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anodic_passion/PycharmProjects/108decillion/.venv/lib/python3.11/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Flatten(input_shape=(5, 11)),  # Flatten the 3D input to 2D\n",
    "        Dense(1000, activation='relu'),\n",
    "        Dense(600, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(400, activation='relu'),\n",
    "        Dense(150, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(3, activation='relu'),\n",
    "        # Reshape((3, 11))\n",
    "        # Dense(55, activation='relu'),\n",
    "        # Dense(3, activation='relu'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='SGD', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b07bf49-3cb0-42ff-b351-25746e0f111c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 242.0918 - val_loss: 0.1671\n",
      "Epoch 2/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3659 - val_loss: 0.1671\n",
      "Epoch 3/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3568 - val_loss: 0.1671\n",
      "Epoch 4/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3538 - val_loss: 0.1671\n",
      "Epoch 5/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3921 - val_loss: 0.1671\n",
      "Epoch 6/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3779 - val_loss: 0.1671\n",
      "Epoch 7/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3487 - val_loss: 0.1671\n",
      "Epoch 8/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3536 - val_loss: 0.1671\n",
      "Epoch 9/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3855 - val_loss: 0.1671\n",
      "Epoch 10/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3696 - val_loss: 0.1671\n",
      "Epoch 11/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3590 - val_loss: 0.1671\n",
      "Epoch 12/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3734 - val_loss: 0.1671\n",
      "Epoch 13/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3754 - val_loss: 0.1671\n",
      "Epoch 14/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3654 - val_loss: 0.1671\n",
      "Epoch 15/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3785 - val_loss: 0.1671\n",
      "Epoch 16/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3491 - val_loss: 0.1671\n",
      "Epoch 17/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3579 - val_loss: 0.1671\n",
      "Epoch 18/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3706 - val_loss: 0.1671\n",
      "Epoch 19/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3679 - val_loss: 0.1671\n",
      "Epoch 20/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3934 - val_loss: 0.1671\n",
      "Epoch 21/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3645 - val_loss: 0.1671\n",
      "Epoch 22/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3747 - val_loss: 0.1671\n",
      "Epoch 23/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3654 - val_loss: 0.1671\n",
      "Epoch 24/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3751 - val_loss: 0.1671\n",
      "Epoch 25/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3817 - val_loss: 0.1671\n",
      "Epoch 26/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3737 - val_loss: 0.1671\n",
      "Epoch 27/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3711 - val_loss: 0.1671\n",
      "Epoch 28/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3642 - val_loss: 0.1671\n",
      "Epoch 29/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3647 - val_loss: 0.1671\n",
      "Epoch 30/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3617 - val_loss: 0.1671\n",
      "Epoch 31/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3650 - val_loss: 0.1671\n",
      "Epoch 32/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3639 - val_loss: 0.1671\n",
      "Epoch 33/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3697 - val_loss: 0.1671\n",
      "Epoch 34/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3648 - val_loss: 0.1671\n",
      "Epoch 35/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3636 - val_loss: 0.1671\n",
      "Epoch 36/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3736 - val_loss: 0.1671\n",
      "Epoch 37/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3879 - val_loss: 0.1671\n",
      "Epoch 38/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3550 - val_loss: 0.1671\n",
      "Epoch 39/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3688 - val_loss: 0.1671\n",
      "Epoch 40/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3912 - val_loss: 0.1671\n",
      "Epoch 41/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3551 - val_loss: 0.1671\n",
      "Epoch 42/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3628 - val_loss: 0.1671\n",
      "Epoch 43/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3618 - val_loss: 0.1671\n",
      "Epoch 44/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3793 - val_loss: 0.1671\n",
      "Epoch 45/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3744 - val_loss: 0.1671\n",
      "Epoch 46/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3780 - val_loss: 0.1671\n",
      "Epoch 47/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3555 - val_loss: 0.1671\n",
      "Epoch 48/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3624 - val_loss: 0.1671\n",
      "Epoch 49/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3900 - val_loss: 0.1671\n",
      "Epoch 50/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3491 - val_loss: 0.1671\n",
      "Epoch 51/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3346 - val_loss: 0.1671\n",
      "Epoch 52/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3638 - val_loss: 0.1671\n",
      "Epoch 53/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3651 - val_loss: 0.1671\n",
      "Epoch 54/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3707 - val_loss: 0.1671\n",
      "Epoch 55/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3883 - val_loss: 0.1671\n",
      "Epoch 56/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3616 - val_loss: 0.1671\n",
      "Epoch 57/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3706 - val_loss: 0.1671\n",
      "Epoch 58/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3487 - val_loss: 0.1671\n",
      "Epoch 59/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3831 - val_loss: 0.1671\n",
      "Epoch 60/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3541 - val_loss: 0.1671\n",
      "Epoch 61/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3590 - val_loss: 0.1671\n",
      "Epoch 62/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3931 - val_loss: 0.1671\n",
      "Epoch 63/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3648 - val_loss: 0.1671\n",
      "Epoch 64/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3756 - val_loss: 0.1671\n",
      "Epoch 65/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3824 - val_loss: 0.1671\n",
      "Epoch 66/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3639 - val_loss: 0.1671\n",
      "Epoch 67/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3617 - val_loss: 0.1671\n",
      "Epoch 68/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3709 - val_loss: 0.1671\n",
      "Epoch 69/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3473 - val_loss: 0.1671\n",
      "Epoch 70/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3508 - val_loss: 0.1671\n",
      "Epoch 71/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3462 - val_loss: 0.1671\n",
      "Epoch 72/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3630 - val_loss: 0.1671\n",
      "Epoch 73/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3686 - val_loss: 0.1671\n",
      "Epoch 74/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3587 - val_loss: 0.1671\n",
      "Epoch 75/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3636 - val_loss: 0.1671\n",
      "Epoch 76/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3612 - val_loss: 0.1671\n",
      "Epoch 77/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3751 - val_loss: 0.1671\n",
      "Epoch 78/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3774 - val_loss: 0.1671\n",
      "Epoch 79/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3806 - val_loss: 0.1671\n",
      "Epoch 80/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3719 - val_loss: 0.1671\n",
      "Epoch 81/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3582 - val_loss: 0.1671\n",
      "Epoch 82/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3631 - val_loss: 0.1671\n",
      "Epoch 83/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3832 - val_loss: 0.1671\n",
      "Epoch 84/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3780 - val_loss: 0.1671\n",
      "Epoch 85/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3826 - val_loss: 0.1671\n",
      "Epoch 86/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3708 - val_loss: 0.1671\n",
      "Epoch 87/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3461 - val_loss: 0.1671\n",
      "Epoch 88/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3976 - val_loss: 0.1671\n",
      "Epoch 89/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3862 - val_loss: 0.1671\n",
      "Epoch 90/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3530 - val_loss: 0.1671\n",
      "Epoch 91/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3520 - val_loss: 0.1671\n",
      "Epoch 92/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3696 - val_loss: 0.1671\n",
      "Epoch 93/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3735 - val_loss: 0.1671\n",
      "Epoch 94/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3556 - val_loss: 0.1671\n",
      "Epoch 95/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3552 - val_loss: 0.1671\n",
      "Epoch 96/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3673 - val_loss: 0.1671\n",
      "Epoch 97/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3693 - val_loss: 0.1671\n",
      "Epoch 98/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3515 - val_loss: 0.1671\n",
      "Epoch 99/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3542 - val_loss: 0.1671\n",
      "Epoch 100/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3704 - val_loss: 0.1671\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b15e15-f40b-49c1-b454-5134c80dac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78a6fabf-bc58-497d-8003-03c9f5f1d68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0.]], dtype=float32), [[0.03], [0.15], [0.01]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [[0.0, 0.01, -0.08, -0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [-0.01, 0.05, -0.03, 0.04, 0.01, 0.09, -0.03, -0.04, 0.01, 10226.0, -17.22], [0.02, 0.04, -0.05, -0.01, 0.03, 0.19, -0.05, -0.06, 0.0, 9028.0, 5.19], [-0.01, 0.0, -0.05, 0.0, 0.04, 0.27, -0.06, -0.07, -0.02, -3834.0, -26.85], [0.0, 0.05, -0.05, 0.0, 0.08, 0.31, -0.08, -0.07, -0.05, 2136.0, -6.22]]\n",
    "y_test = [[0.03], [0.15], [0.01]]\n",
    "y_pred = model.predict(X[0:1])\n",
    "y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875b5daf-9a85-4aa8-a83c-c52fee1f5d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example for the first feature (e.g., Close price)\n",
    "plt.plot(y_test, label='Actual Close')\n",
    "plt.plot(y_pred, label='Predicted Close')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
